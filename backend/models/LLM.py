import requests
import json
import re
from backend.utils.struct_validation import validate_json

# Ollama server endpoint
OLLAMA_API_URL = "http://localhost:11434/api/chat"

def chat_with_model(prompt: str, model_name: str = "llama2"):
    """
    Interact with the LLM model to generate a response for the given prompt.

    Args:
        prompt (str): The input prompt for the LLM.
        model_name (str): The name of the model to use.

    Returns:
        str: The response generated by the LLM.
    """
    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "stream": False
    }
    print('-------------------------------------------------------------------\n\n\n')
    print(prompt)
    print('------------------------------------------------------------------\n\n\n')
    try:
        # Send a request to the LLM API
        response = requests.post(OLLAMA_API_URL, json=payload)

        # Handle API errors
        if response.status_code != 200:
            return f"Error: Unable to process the request. Status Code: {response.status_code}"

        # Extract the content from the response
        data = response.json()
        message_content = data.get("message", {}).get("content", "").strip()

        # Post-process the response (optional cleanup or formatting)
        if not message_content:
            return "The model did not provide a valid response."

        return message_content

    except requests.exceptions.RequestException as e:
        return f"Error: Failed to connect to the LLM API. Details: {str(e)}"
    except json.JSONDecodeError:
        return "Error: Invalid response from the LLM API."


import json
import re
import requests

OLLAMA_API_URL = "http://localhost:11434/api/chat"


def extract_preferences(user_input: str, current_data: dict, model_name: str = "llama2") -> dict:
    """
    Extract structured preferences, budget, and location from user input using LLaMA via Ollama.

    Args:
        user_input (str): The user's raw text input.
        current_data (dict): The user's current preferences, budget, and location.
        model_name (str): The model to use (default: "llama3.2").

    Returns:
        dict: Updated preferences, budget, and location in structured format.
    """
    prompt = f"""
    You are a helpful assistant. Your task is to extract user preferences, budget, and location from their input and return the result as valid JSON.
    Ensure that the JSON response is valid and complete.

    **Instructions**:
    - Analyze the user's input.
    - Match their preferences to one or more of the following predefined types:
    - `historical`: Interest in historical sites or landmarks.
    - `food`: Interest in trying different cuisines or food experiences.
    - `adventure`: Interest in adventurous activities like hiking, rafting, etc.
    - `relaxation`: Interest in relaxing activities like spas, beaches, or parks.
    - `cultural`: Interest in cultural activities like museums, art galleries, or performances.

    - Assign one of the following intensity levels to each preference:
    - `low`: Mild interest or occasional participation.
    - `moderate`: Considerable interest and active participation.
    - `high`: Passionate interest and a strong desire to prioritize this activity.

    - Extract the user's budget:
    - `low`: Limited budget, prioritizes cost-effective options.
    - `average`: Moderate budget, balances cost and experience.
    - `comfortable`: Higher budget, prioritizes comfort and convenience.
    - `luxury`: Premium budget, focuses on high-end experiences.
    - If the budget is not mentioned, assume it is `average`.

    - Extract the user's location preference:
    - If the user mentions a specific location, extract it (e.g., "Mumbai").
    - If the user mentions multiple locations or is unclear, set location to `null`.
    - If no location is mentioned, retain their current location if known; otherwise, set location to `null`.
    u are a helpful assistant. Your task is to extract user preferences, budget, and location from their input and return the result as valid JSON.
    Ensure that the JSON response is valid and complete.

    **Instructions**:
    - Analyze the user's input.
    - Match their preferences to one or more of the following predefined types:
    - `historical`: Interest in historical sites or landmarks.
    - `food`: Interest in trying different cuisines or food experiences.
    - `adventure`: Interest in adventurous activities like hiking, rafting, etc.
    - `relaxation`: Interest in relaxing activities like spas, beaches, or parks.
    - `cultural`: Interest in cultural activities like museums, art galleries, or performances.

    - Assign one of the following intensity levels to each preference:
    - `low`: Mild interest or occasional participation.
    - `moderate`: Con

    **Important**:
    - For ambiguous inputs like "Visit Mumbai next", prioritize extracting the location and set preferences and budget to defaults if not mentioned.
    - Always output valid JSON as your response. Do not include explanations, code, or anything outside the JSON format.

    **Very Very Important**:
    - Ensure the JSON Format is correct and complete.

    **Expected JSON Output Format**:
    {{
    "preferences": [
        {{
        "type": "<type>",
        "intensity": "<low|moderate|high>"
        }},
        ...
    ],
    "budget": "<low|average|comfortable|luxury>",
    "location": "<city|region|null>"
    }}

    Now process this:
    "{user_input}"
    """

    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "stream": False
    }

    try:
        response = requests.post(OLLAMA_API_URL, json=payload)

        if response.status_code != 200:
            return {"error": f"Error {response.status_code}: {response.text}"}

        data = response.json()
        raw_content = data.get("message", {}).get("content", "")
        print("Raw LLM Output:", raw_content)

        # Extract JSON data from the response
        json_match = re.search(r"\{.*\}", raw_content, re.DOTALL)
        if json_match:
            extracted_data = json.loads(json_match.group(0))
        else:
            print("No valid JSON found. Using current data as fallback.")
            extracted_data = {}

        # Merge extracted data with current values
        merged_data = validate_and_fill_defaults(extracted_data, current_data)
        return merged_data

    except Exception as e:
        print(f"Error: {str(e)}")
        return validate_and_fill_defaults({}, current_data)
    




def validate_and_fill_defaults(data: dict, current_data: dict) -> dict:
    """
    Validate and fill missing values in the extracted data.

    Args:
        data (dict): Extracted data from the LLM.
        current_data (dict): The user's current preferences, budget, and location.

    Returns:
        dict: Validated data with defaults for missing fields.
    """
    defaults = {
        "preferences": current_data.get("preferences", []),
        "budget": current_data.get("budget", "average"),
        "location": current_data.get("location", None)
    }

    # Validate preferences
    preferences = data.get("preferences", [])
    validated_preferences = [
        pref for pref in preferences
        if "type" in pref and "intensity" in pref and pref["type"] in {"historical", "food", "adventure", "relaxation", "cultural"}
    ]
    defaults["preferences"] = validated_preferences or defaults["preferences"]

    # Validate budget
    budget = data.get("budget", current_data.get("budget", "average"))
    defaults["budget"] = budget if budget in {"low", "average", "comfortable", "luxury"} else current_data.get("budget", "average")

    # Validate location
    location = data.get("location", current_data.get("location", None))
    defaults["location"] = location if isinstance(location, str) else current_data.get("location", None)

    return defaults

